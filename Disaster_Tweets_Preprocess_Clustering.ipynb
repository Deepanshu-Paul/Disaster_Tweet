{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deepanshu-Paul/Disaster_Tweet/blob/main/Disaster_Tweets_Preprocess_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Now you can access files in your Drive like regular files.\n",
        "# Example: Reading a CSV from Drive\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/NLP Practice/Disaster tweets/sample_submission.csv') # Replace with the correct path\n",
        "#print(df)\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/NLP Practice/Disaster tweets/train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/NLP Practice/Disaster tweets/test.csv')"
      ],
      "metadata": {
        "id": "0gVJo20UadWv",
        "outputId": "722e21f3-fbc8-4847-97b4-fe704d86de4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "zwFnJsE6vjf8",
        "outputId": "361411e6-c8d2-4fc9-9672-fe646c029d97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['test.csv', 'sample_submission.csv', 'train.csv']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.listdir('/content/drive/MyDrive/NLP Practice/Disaster tweets'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Data Cleaning And Preprocessing\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab') # Download the punkt_tab data for sentence tokenization"
      ],
      "metadata": {
        "id": "AAjby4bcdqjB",
        "outputId": "8da85561-4c1b-405f-fab0-5db962b32a71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus=\"\"\"Hello Welcome,to Krish Naik's NLP Tutorials.\n",
        "Please do watch the entire course! to become expert in NLP.\n",
        "\"\"\"\n",
        "#print(corpus)\n",
        "from nltk.tokenize import sent_tokenize\n",
        "documents = sent_tokenize(corpus)\n",
        "#print(documents)"
      ],
      "metadata": {
        "id": "5v_c1481eiPT"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "type(documents)"
      ],
      "metadata": {
        "id": "yN9OT5wFixpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "words = word_tokenize(corpus)\n",
        "#print(words)"
      ],
      "metadata": {
        "id": "0SI75QP8i6PA"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in documents:\n",
        "  print(word_tokenize(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPgSlzykjDtg",
        "outputId": "a9da7f9c-4dff-44e9-9830-bcaa3b68f59e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'Welcome', ',', 'to', 'Krish', 'Naik', \"'s\", 'NLP', 'Tutorials', '.']\n",
            "['Please', 'do', 'watch', 'the', 'entire', 'course', '!']\n",
            "['to', 'become', 'expert', 'in', 'NLP', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import wordpunct_tokenize\n",
        "#wordpunct_tokenize(corpus)"
      ],
      "metadata": {
        "id": "dwPJT_oRjRw8"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwnNlNIEwoZ8"
      },
      "source": [
        "To learn more about accelerating pandas on Colab, see the [10 minute guide](https://colab.research.google.com/github/rapidsai-community/showcase/blob/main/getting_started_tutorials/cudf_pandas_colab_demo.ipynb) or\n",
        " [US stock market data analysis demo](https://colab.research.google.com/github/rapidsai-community/showcase/blob/main/getting_started_tutorials/cudf_pandas_stocks_demo.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "#tokenizer.tokenize(corpus)"
      ],
      "metadata": {
        "id": "FPE_wBAjjkPd"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['text_processed'] = train_df['text'].str.lower()\n",
        "#train_df.head()"
      ],
      "metadata": {
        "id": "JulXNRF4kVgj"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# Download the 'wordnet' dataset\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def clean_text_stopwords(text):\n",
        "  text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "  text = text.lower()\n",
        "  # Instantiate the WordNetLemmatizer\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  words =text.split()\n",
        "  words = [words for words in words if words not in stopwords.words('english')]\n",
        "  text = ' '.join(words)\n",
        "   # Lemmatize each word in the list\n",
        "  words = [lemmatizer.lemmatize(word, pos='v') for word in words]\n",
        "  text = ' '.join(words)\n",
        "  words = [lemmatizer.lemmatize(word, pos='n') for word in words]\n",
        "  text = ' '.join(words)\n",
        "  words = [lemmatizer.lemmatize(word, pos='a') for word in words]\n",
        "  text = ' '.join(words)\n",
        "\n",
        "  return text\n",
        "\n",
        "train_df['text_processed'] = train_df['text'].apply(clean_text_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNqx2O2ik9_r",
        "outputId": "7a20b51e-bb7c-41ba-fb7b-97fd87e22897"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Create TF-IDF And NGrams\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=2000, ngram_range=(2,3))\n",
        "tfidf_matrix = vectorizer.fit_transform(train_df['text_processed']).toarray()"
      ],
      "metadata": {
        "id": "eCMPACxt7AOy"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Create a KMeans instance with the desired number of clusters\n",
        "# For example, let's use 3 clusters:\n",
        "kmeans = KMeans(n_clusters=3, random_state=0, n_init='auto')\n",
        "\n",
        "# Fit the KMeans model to your data (e.g., tfidf_matrix)\n",
        "kmeans.fit(tfidf_matrix)\n",
        "\n",
        "# Now you can access the labels\n",
        "train_df['cluster_kmeans'] = kmeans.labels_\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "e50f42dsBDj8"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0T_V-zW8cM7",
        "outputId": "7450d0e7-6d02-4dd5-b313-44f74c62cff0"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_optimal_clusters(tfidf_matrix, max_clusters=10):\n",
        "    \"\"\"Finds the optimal number of clusters using silhouette score.\"\"\"\n",
        "    best_score = -1\n",
        "    best_n_clusters = 2  # Initialize with a default value\n",
        "    for n_clusters in range(2, max_clusters + 1):\n",
        "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10) # n_init added for KMeans > 1.0\n",
        "        kmeans.fit(tfidf_matrix)\n",
        "        labels = kmeans.labels_\n",
        "        score = silhouette_score(tfidf_matrix, labels)\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_n_clusters = n_clusters\n",
        "    return best_n_clusters"
      ],
      "metadata": {
        "id": "890SrI0QBpaX"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_clusters = find_optimal_clusters(tfidf_matrix, max_clusters=10)"
      ],
      "metadata": {
        "id": "Wh1WsFYnDV88"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10) # Using provided num_clusters\n",
        "kmeans.fit(tfidf_matrix)\n",
        "train_df['cluster_kmeans'] = kmeans.labels_"
      ],
      "metadata": {
        "id": "vM7L3rcUDyxk"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gensim  # Ensure you have the latest version of Gensim\n",
        "import gensim\n",
        "from gensim.models import word2vec # Word2vec is a submodule\n",
        "#from gensim.models import KeyedVectors\n",
        "import gensim.downloader as api\n",
        "wv = api.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL52-nzB8etf",
        "outputId": "05ff3498-ff0a-4a88-caf8-4896aba17f2a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_word2vec(sentences, vector_size=3000, window=5, min_count=1, sg=0):  # Added parameters\n",
        "    \"\"\"Trains a Word2Vec model.\"\"\"\n",
        "    # Use the Word2Vec class to create a new model\n",
        "    model = gensim.models.Word2Vec(sentences, vector_size=vector_size, window=window, min_count=min_count, sg=sg)\n",
        "    return model"
      ],
      "metadata": {
        "id": "XEJjlEtKE_yV"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def get_average_word_embedding(tokens, model):\n",
        "  embeddings = []\n",
        "  for word in tokens:\n",
        "    if word in model.wv:\n",
        "      embeddings.append(model.wv[word])\n",
        "    if embeddings:\n",
        "      return np.mean(embeddings, axis = 0)\n",
        "    else:\n",
        "      return np.zeros(model.vector_size)"
      ],
      "metadata": {
        "id": "WFNDuPV0Fn9x"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = train_df['text_processed'].tolist()\n",
        "# If training Word2Vec\n",
        "word2vec_model = train_word2vec(sentences, 3000, 5, 1, 0)\n",
        "train_df['tweet_embedding'] = train_df['text_processed'].apply(lambda tokens: get_average_word_embedding(tokens, word2vec_model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ2lpzufHBTA",
        "outputId": "2773caab-aac0-4235-c49d-425662ffc476"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['tweet_embedding'] = train_df['text_processed'].apply(lambda tokens: get_average_word_embedding(tokens, word2vec_model))\n"
      ],
      "metadata": {
        "id": "OfgerQeEJM5b"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert embeddings to a matrix for KMeans\n",
        "embedding_matrix = np.vstack(train_df['tweet_embedding'].values)\n",
        "\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)\n",
        "kmeans.fit(embedding_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "Ky9jMwUKJeNE",
        "outputId": "a7c021e0-80ce-4830-d64d-bf12d45f6ada"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(n_clusters=10, n_init=10, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=10, n_init=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>KMeans</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.cluster.KMeans.html\">?<span>Documentation for KMeans</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>KMeans(n_clusters=10, n_init=10, random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['wv_cluster'] = kmeans.labels_"
      ],
      "metadata": {
        "id": "1C6x54xRJ-Gi"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: compare and finalize which is better word2vec or tfidf\n",
        "\n",
        "# Assuming 'train_df' is your DataFrame with 'cluster_kmeans' and 'wv_cluster' columns\n",
        "# and the necessary columns for analysis are already created.\n",
        "\n",
        "def compare_clustering_results(df):\n",
        "    \"\"\"Compares the clustering results of TF-IDF and Word2Vec and provides a recommendation.\"\"\"\n",
        "\n",
        "    # 1. Compare Cluster Distributions:\n",
        "    print(\"Cluster Distribution (TF-IDF):\\n\", df['cluster_kmeans'].value_counts(normalize=True))\n",
        "    print(\"\\nCluster Distribution (Word2Vec):\\n\", df['wv_cluster'].value_counts(normalize=True))\n",
        "\n",
        "    # 2. Identify Common and Different Cluster Assignments:\n",
        "    common_assignments = df[df['cluster_kmeans'] == df['wv_cluster']]\n",
        "    print(f\"\\nNumber of tweets with common cluster assignments: {len(common_assignments)}\")\n",
        "\n",
        "    different_assignments = df[df['cluster_kmeans'] != df['wv_cluster']]\n",
        "    print(f\"\\nNumber of tweets with different cluster assignments: {len(different_assignments)}\")\n",
        "\n",
        "    # 3. Analyze tweets with differing assignments (example - first 5):\n",
        "    print(\"\\nExamples of tweets with different cluster assignments (first 5):\")\n",
        "    for index, row in different_assignments.head(5).iterrows():\n",
        "        print(f\"Original Text: {row['text'][:100]}...\")\n",
        "        print(f\"TF-IDF Cluster: {row['cluster_kmeans']}, Word2Vec Cluster: {row['wv_cluster']}\")\n",
        "        print(\"-\" * 20)\n",
        "\n",
        "    # 4.  Recommendation based on analysis:\n",
        "    if len(common_assignments) > len(different_assignments):\n",
        "        print(\"\\nRecommendation:\")\n",
        "        print(\"The clustering results are largely similar.  Consider using the method that is more efficient for your purpose.\")\n",
        "        if (df['cluster_kmeans'].value_counts(normalize=True).max() < 0.5 and\n",
        "                df['wv_cluster'].value_counts(normalize=True).max() < 0.5):\n",
        "            print(\"Both methods show reasonable cluster distributions. Consider using TF-IDF due to its simplicity and efficiency\")\n",
        "        else:\n",
        "            print(\"TF-IDF is generally faster and simpler. Consider using TF-IDF.\")\n",
        "            print(\"Word2Vec is potentially more semantically rich but computationally intensive.\")\n",
        "\n",
        "    else:\n",
        "        print(\"\\nRecommendation:\")\n",
        "        print(\"The clustering results show substantial differences.\")\n",
        "        print(\"Further investigation is needed to determine the best approach for your specific task.\")\n",
        "        print(\"Consider examining the examples with differing assignments to understand the discrepancies.\")\n",
        "        print(\"If semantic similarity is crucial, Word2Vec might be preferable after further tuning.\")\n",
        "\n",
        "# Call the function to compare results:\n",
        "compare_clustering_results(train_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDhj7A53P5yq",
        "outputId": "600e0876-bd6b-42ee-97a4-96ec92333986"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Distribution (TF-IDF):\n",
            " cluster_kmeans\n",
            "0    0.964797\n",
            "4    0.007356\n",
            "6    0.006436\n",
            "5    0.004335\n",
            "1    0.004072\n",
            "7    0.003678\n",
            "9    0.003547\n",
            "3    0.002890\n",
            "8    0.001970\n",
            "2    0.000919\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Cluster Distribution (Word2Vec):\n",
            " wv_cluster\n",
            "1    0.272691\n",
            "0    0.189413\n",
            "5    0.121897\n",
            "4    0.110075\n",
            "7    0.069224\n",
            "3    0.062919\n",
            "8    0.051360\n",
            "2    0.051228\n",
            "9    0.048995\n",
            "6    0.022199\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Number of tweets with common cluster assignments: 1411\n",
            "\n",
            "Number of tweets with different cluster assignments: 6202\n",
            "\n",
            "Examples of tweets with different cluster assignments (first 5):\n",
            "Original Text: Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all...\n",
            "TF-IDF Cluster: 0, Word2Vec Cluster: 1\n",
            "--------------------\n",
            "Original Text: Forest fire near La Ronge Sask. Canada...\n",
            "TF-IDF Cluster: 7, Word2Vec Cluster: 9\n",
            "--------------------\n",
            "Original Text: All residents asked to 'shelter in place' are being notified by officers. No other evacuation or she...\n",
            "TF-IDF Cluster: 0, Word2Vec Cluster: 4\n",
            "--------------------\n",
            "Original Text: 13,000 people receive #wildfires evacuation orders in California ...\n",
            "TF-IDF Cluster: 0, Word2Vec Cluster: 8\n",
            "--------------------\n",
            "Original Text: Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school ...\n",
            "TF-IDF Cluster: 0, Word2Vec Cluster: 1\n",
            "--------------------\n",
            "\n",
            "Recommendation:\n",
            "The clustering results show substantial differences.\n",
            "Further investigation is needed to determine the best approach for your specific task.\n",
            "Consider examining the examples with differing assignments to understand the discrepancies.\n",
            "If semantic similarity is crucial, Word2Vec might be preferable after further tuning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: run dbscan on tfidf_matrix\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "# Assuming 'tfidf_matrix' is already defined from the provided code\n",
        "\n",
        "# Create a DBSCAN instance\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=5) # Adjust eps and min_samples as needed\n",
        "\n",
        "# Fit the DBSCAN model to the tfidf_matrix\n",
        "dbscan.fit(tfidf_matrix)\n",
        "\n",
        "# Get the cluster labels\n",
        "train_df['cluster_dbscan'] = dbscan.labels_\n",
        "\n",
        "# Now you can analyze the results, for example:\n",
        "print(train_df['cluster_dbscan'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mu69vQwhQcoZ",
        "outputId": "ad474a16-5898-4cac-8e6d-d555ce673217"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cluster_dbscan\n",
            " 0      4249\n",
            "-1      1490\n",
            " 39       37\n",
            " 47       33\n",
            " 24       32\n",
            "        ... \n",
            " 140       5\n",
            " 139       5\n",
            " 138       5\n",
            " 73        5\n",
            " 101       5\n",
            "Name: count, Length: 204, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: run dbscan on word2vec matrix\n",
        "\n",
        "# Assuming 'embedding_matrix' is already defined from the provided code\n",
        "\n",
        "# Create a DBSCAN instance\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=5) # Adjust eps and min_samples as needed\n",
        "\n",
        "# Fit the DBSCAN model to the embedding_matrix\n",
        "dbscan.fit(embedding_matrix)\n",
        "\n",
        "# Get the cluster labels\n",
        "train_df['wv_cluster_dbscan'] = dbscan.labels_\n",
        "\n",
        "# Now you can analyze the results, for example:\n",
        "print(train_df['wv_cluster_dbscan'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeFFVHEGQpyz",
        "outputId": "1abc1f32-31a8-4257-8ccb-166f2c413111"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wv_cluster_dbscan\n",
            "10    689\n",
            "11    527\n",
            "6     479\n",
            "2     434\n",
            "17    424\n",
            "14    424\n",
            "15    415\n",
            "9     404\n",
            "0     401\n",
            "3     391\n",
            "7     390\n",
            "8     388\n",
            "1     373\n",
            "12    307\n",
            "5     273\n",
            "4     255\n",
            "13    240\n",
            "16    173\n",
            "18    145\n",
            "20    136\n",
            "22    120\n",
            "21    100\n",
            "19     76\n",
            "23     22\n",
            "24     20\n",
            "25      7\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: compare between the above 2 codes\n",
        "\n",
        "def compare_clustering_results(df):\n",
        "    \"\"\"Compares the clustering results of TF-IDF and Word2Vec and provides a recommendation.\"\"\"\n",
        "\n",
        "    # 1. Compare Cluster Distributions:\n",
        "    print(\"Cluster Distribution (TF-IDF):\\n\", df['cluster_kmeans'].value_counts(normalize=True))\n",
        "    print(\"\\nCluster Distribution (Word2Vec):\\n\", df['wv_cluster'].value_counts(normalize=True))\n",
        "\n",
        "    # 2. Identify Common and Different Cluster Assignments:\n",
        "    common_assignments = df[df['cluster_kmeans'] == df['wv_cluster']]\n",
        "    print(f\"\\nNumber of tweets with common cluster assignments: {len(common_assignments)}\")\n",
        "\n",
        "    different_assignments = df[df['cluster_kmeans'] != df['wv_cluster']]\n",
        "    print(f\"\\nNumber of tweets with different cluster assignments: {len(different_assignments)}\")\n",
        "\n",
        "    # 3. Analyze tweets with differing assignments (example - first 5):\n",
        "    print(\"\\nExamples of tweets with different cluster assignments (first 5):\")\n",
        "    for index, row in different_assignments.head(5).iterrows():\n",
        "        print(f\"Original Text: {row['text'][:100]}...\")\n",
        "        print(f\"TF-IDF Cluster: {row['cluster_kmeans']}, Word2Vec Cluster: {row['wv_cluster']}\")\n",
        "        print(\"-\" * 20)\n",
        "\n",
        "    # 4.  Recommendation based on analysis:\n",
        "    if len(common_assignments) > len(different_assignments):\n",
        "        print(\"\\nRecommendation:\")\n",
        "        print(\"The clustering results are largely similar.  Consider using the method that is more efficient for your purpose.\")\n",
        "        if (df['cluster_kmeans'].value_counts(normalize=True).max() < 0.5 and\n",
        "                df['wv_cluster'].value_counts(normalize=True).max() < 0.5):\n",
        "            print(\"Both methods show reasonable cluster distributions. Consider using TF-IDF due to its simplicity and efficiency\")\n",
        "        else:\n",
        "            print(\"TF-IDF is generally faster and simpler. Consider using TF-IDF.\")\n",
        "            print(\"Word2Vec is potentially more semantically rich but computationally intensive.\")\n",
        "\n",
        "    else:\n",
        "        print(\"\\nRecommendation:\")\n",
        "        print(\"The clustering results show substantial differences.\")\n",
        "        print(\"Further investigation is needed to determine the best approach for your specific task.\")\n",
        "        print(\"Consider examining the examples with differing assignments to understand the discrepancies.\")\n",
        "        print(\"If semantic similarity is crucial, Word2Vec might be preferable after further tuning.\")\n",
        "\n",
        "# Call the function to compare results:\n",
        "compare_clustering_results(train_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl6-_QIeQ4Xf",
        "outputId": "ce6e9fa2-d03c-4176-f66c-2f4744d228f8"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Distribution (TF-IDF):\n",
            " cluster_kmeans\n",
            "0    0.964797\n",
            "4    0.007356\n",
            "6    0.006436\n",
            "5    0.004335\n",
            "1    0.004072\n",
            "7    0.003678\n",
            "9    0.003547\n",
            "3    0.002890\n",
            "8    0.001970\n",
            "2    0.000919\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Cluster Distribution (Word2Vec):\n",
            " wv_cluster\n",
            "1    0.272691\n",
            "0    0.189413\n",
            "5    0.121897\n",
            "4    0.110075\n",
            "7    0.069224\n",
            "3    0.062919\n",
            "8    0.051360\n",
            "2    0.051228\n",
            "9    0.048995\n",
            "6    0.022199\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Number of tweets with common cluster assignments: 1411\n",
            "\n",
            "Number of tweets with different cluster assignments: 6202\n",
            "\n",
            "Examples of tweets with different cluster assignments (first 5):\n",
            "Original Text: Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all...\n",
            "TF-IDF Cluster: 0, Word2Vec Cluster: 1\n",
            "--------------------\n",
            "Original Text: Forest fire near La Ronge Sask. Canada...\n",
            "TF-IDF Cluster: 7, Word2Vec Cluster: 9\n",
            "--------------------\n",
            "Original Text: All residents asked to 'shelter in place' are being notified by officers. No other evacuation or she...\n",
            "TF-IDF Cluster: 0, Word2Vec Cluster: 4\n",
            "--------------------\n",
            "Original Text: 13,000 people receive #wildfires evacuation orders in California ...\n",
            "TF-IDF Cluster: 0, Word2Vec Cluster: 8\n",
            "--------------------\n",
            "Original Text: Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school ...\n",
            "TF-IDF Cluster: 0, Word2Vec Cluster: 1\n",
            "--------------------\n",
            "\n",
            "Recommendation:\n",
            "The clustering results show substantial differences.\n",
            "Further investigation is needed to determine the best approach for your specific task.\n",
            "Consider examining the examples with differing assignments to understand the discrepancies.\n",
            "If semantic similarity is crucial, Word2Vec might be preferable after further tuning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# prompt: compare kmeans with word2vec with dbscan with word2vec results\n",
        "\n",
        "def compare_clustering_results_extended(df):\n",
        "    \"\"\"Compares various clustering results and provides a detailed analysis.\"\"\"\n",
        "\n",
        "    clustering_methods = {\n",
        "        'KMeans (TF-IDF)': 'cluster_kmeans',\n",
        "        'KMeans (Word2Vec)': 'wv_cluster',\n",
        "        'DBSCAN (TF-IDF)': 'cluster_dbscan',\n",
        "        'DBSCAN (Word2Vec)': 'wv_cluster_dbscan'\n",
        "    }\n",
        "\n",
        "    for method1_name, method1_col in clustering_methods.items():\n",
        "        for method2_name, method2_col in clustering_methods.items():\n",
        "            if method1_name != method2_name:\n",
        "                print(f\"\\nComparing {method1_name} with {method2_name}:\")\n",
        "\n",
        "                # Cluster Distributions\n",
        "                print(f\"\\nCluster Distribution ({method1_name}):\\n\", df[method1_col].value_counts(normalize=True))\n",
        "                print(f\"\\nCluster Distribution ({method2_name}):\\n\", df[method2_col].value_counts(normalize=True))\n",
        "\n",
        "                # Common and Different Assignments\n",
        "                common_assignments = df[df[method1_col] == df[method2_col]]\n",
        "                print(f\"\\nNumber of tweets with common cluster assignments: {len(common_assignments)}\")\n",
        "\n",
        "                different_assignments = df[df[method1_col] != df[method2_col]]\n",
        "                print(f\"\\nNumber of tweets with different cluster assignments: {len(different_assignments)}\")\n",
        "\n",
        "                # Example Tweets with Different Assignments\n",
        "                print(f\"\\nExamples of tweets with different cluster assignments (first 5):\")\n",
        "                for index, row in different_assignments.head(5).iterrows():\n",
        "                    print(f\"Original Text: {row['text'][:100]}...\")\n",
        "                    print(f\"{method1_name} Cluster: {row[method1_col]}, {method2_name} Cluster: {row[method2_col]}\")\n",
        "                    print(\"-\" * 20)\n",
        "\n",
        "\n",
        "# Call the function to compare results:\n",
        "compare_clustering_results_extended(train_df)\n"
      ],
      "metadata": {
        "id": "Orwi66F-RGEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Disaster analysis using Naive Bayes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n"
      ],
      "metadata": {
        "id": "76H33z7slpET"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}